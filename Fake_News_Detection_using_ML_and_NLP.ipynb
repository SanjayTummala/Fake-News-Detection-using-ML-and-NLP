{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mhxd6QKzWoUU",
        "s58oooRWW3hT",
        "4wX3j9csXEIg",
        "Tt1J7mkgXZlP",
        "886K25r2Y48Z"
      ],
      "authorship_tag": "ABX9TyNf9caf5fl/eDajPI5xVqSo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayTummala/Fake-News-Detection-using-ML-and-NLP/blob/main/Fake_News_Detection_using_ML_and_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Import Libraries**"
      ],
      "metadata": {
        "id": "mhxd6QKzWoUU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jdnGpWkPzjD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "!pip install empath\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Import Dataset**"
      ],
      "metadata": {
        "id": "s58oooRWW3hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "df_true = pd.read_csv(\"True.csv\")\n",
        "df_fake = pd.read_csv(\"Fake.csv\")"
      ],
      "metadata": {
        "id": "8CVvIAfxQ-BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Perform Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "4wX3j9csXEIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add a target class column to indicate whether the news is real or fake\n",
        "df_true['isfake'] = 1\n",
        "df_true.head()"
      ],
      "metadata": {
        "id": "BVaQLpsQUul7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake['isfake'] = 0\n",
        "df_fake.head()"
      ],
      "metadata": {
        "id": "Ubeql8WfV4cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate Real and Fake News\n",
        "df = pd.concat([df_true, df_fake]).reset_index(drop = True)\n",
        "df"
      ],
      "metadata": {
        "id": "Dpuj9WCOV-qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = ['date'], inplace = True)"
      ],
      "metadata": {
        "id": "NN7AxenbWBju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine title and text together\n",
        "df['original'] = df['title'] + ' ' + df['text']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JHuEZQYyWEiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['original'][0]"
      ],
      "metadata": {
        "id": "RudI0JN7WHiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jH7fm-y6Wmze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.Perform Data Cleaning**"
      ],
      "metadata": {
        "id": "Tt1J7mkgXZlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "id": "2qCDde48WK86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "metadata": {
        "id": "0Lc8LejlXjkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3 and token not in stop_words:\n",
        "            result.append(token)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "jPvEhFAEXmdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required library\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "# Define the preprocess function\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in STOPWORDS and len(token) > 3:  # Assuming stop_words is not required\n",
        "            result.append(token)\n",
        "    return result\n",
        "\n",
        "# Apply the function to the dataframe\n",
        "df['clean'] = df['original'].apply(preprocess)\n"
      ],
      "metadata": {
        "id": "-oO0ye0MXthO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['original'][0]"
      ],
      "metadata": {
        "id": "rEKUyJ6xYLFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['clean'][0])"
      ],
      "metadata": {
        "id": "Nge7lHUuYOOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "uyu6_jfMYRB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_words = []\n",
        "for i in df.clean:\n",
        "    for j in i:\n",
        "        list_of_words.append(j)"
      ],
      "metadata": {
        "id": "BRza-axhYTQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_words"
      ],
      "metadata": {
        "id": "zULqC6aAYZCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_of_words)"
      ],
      "metadata": {
        "id": "t4T1Amv1YjWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(list(set(list_of_words)))\n",
        "total_words"
      ],
      "metadata": {
        "id": "v1vrtesCYmZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_joined'] = df['clean'].apply(lambda x: \" \".join(x))"
      ],
      "metadata": {
        "id": "j7KTAAeAYplI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "2MFPtXgtYwUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_joined'][0]"
      ],
      "metadata": {
        "id": "PhwmGfwRZUFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.Visualize Cleaned Up Dataset**"
      ],
      "metadata": {
        "id": "886K25r2Y48Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "pWbmdXPIY14U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot the number of samples in 'subject'\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.countplot(y=\"subject\", data=df)\n",
        "plt.title(\"Number of Samples in Each Subject\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Subject\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ldapZy8jZIes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot the count of 0 and 1 in the 'isfake' column\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=\"isfake\", data=df, palette=\"coolwarm\")\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Count of 0 and 1 in 'isfake'\")\n",
        "plt.xlabel(\"Is Fake (0 or 1)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks([0, 1], labels=[\"Not Fake (0)\", \"Fake (1)\"])  # Optional for custom labels\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ImsA0Y40ZzsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required library\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(20, 20))\n",
        "wc = WordCloud(\n",
        "    max_words=2000,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    stopwords=stop_words  # Ensure stop_words is defined earlier\n",
        ").generate(\" \".join(df[df.isfake == 1].clean_joined))\n",
        "\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")  # Turn off axes for better visualization\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WhxSfq4oaYXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required library\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Plot the word cloud for text that is not fake (isfake == 0)\n",
        "plt.figure(figsize=(20, 20))\n",
        "wc = WordCloud(\n",
        "    max_words=2000,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    stopwords=stop_words  # Ensure stop_words is defined earlier\n",
        ").generate(\" \".join(df[df.isfake == 0].clean_joined))\n",
        "\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")  # Turn off axes for better visualization\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wbYr_F69a2td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.Confusion Matrix**"
      ],
      "metadata": {
        "id": "5dRXPSDHhYp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "t6AmfJvQdn6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df' is your DataFrame containing the 'clean_joined' column with preprocessed text\n",
        "# And the 'isfake' column contains the target labels (binary classification)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['clean_joined'], df['isfake'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "tfidf1_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data (do not fit again, only transform using the already fitted vectorizer)\n",
        "tfidf1_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize the Multinomial Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# Train the model using the training data\n",
        "clf.fit(tfidf1_train, Y_train)\n",
        "\n",
        "# Save the trained model to a file using pickle\n",
        "pickle.dump(clf, open('tfidf_nb', 'wb'))\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred = clf.predict(tfidf1_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "score = metrics.accuracy_score(Y_test, pred)\n",
        "print(\"Accuracy with Multinomial Naive Bayes:   %0.3f\" % score)\n"
      ],
      "metadata": {
        "id": "B4ZQiogbhCFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(Y_test, pred, labels=[0, 1])  # Assuming 0 = 'Fake' and 1 = 'Real'\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot the confusion matrix\n",
        "plot_confusion_matrix(cm, classes=['Fake', 'Real'])\n"
      ],
      "metadata": {
        "id": "4RXrfQXkhlQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(tfidf1_train, Y_train)\n",
        "pickle.dump(clf, open('tfidf_rf', 'wb'))\n",
        "pred = clf.predict(tfidf1_test)\n",
        "score = metrics.accuracy_score(Y_test, pred)\n",
        "print(\"Accuracy with RandomForestClassifier:   %0.3f\" % score)"
      ],
      "metadata": {
        "id": "IIawyJoth-Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix with numeric labels (0 = Fake, 1 = Real)\n",
        "cm = confusion_matrix(Y_test, pred, labels=[0, 1])  # Assuming 0 = 'Fake' and 1 = 'Real'\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot the confusion matrix with proper class names\n",
        "plot_confusion_matrix(cm, classes=['Fake', 'Real'])\n"
      ],
      "metadata": {
        "id": "WpOOvuqWj_bq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}